{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb6c62f1-cc7c-4efd-b43d-668fb6be57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2\n",
      "X1  1.000000  0.516735\n",
      "X2  0.516735  1.000000\n",
      "  feature       VIF\n",
      "0      X1  7.778669\n",
      "1      X2  7.778669\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Path to dataset files: C:\\Users\\Admin\\.cache\\kagglehub\\datasets\\yasserh\\bmidataset\\versions\\1\n",
      "   Gender  Height  Weight  Index\n",
      "0    Male     174      96      4\n",
      "1    Male     189      87      2\n",
      "2  Female     185     110      4\n",
      "3  Female     195     104      3\n",
      "4    Male     149      61      3\n",
      "          Gender    Height    Weight\n",
      "Gender  1.000000  0.017677 -0.009523\n",
      "Height  0.017677  1.000000  0.000446\n",
      "Weight -0.009523  0.000446  1.000000\n",
      "  feature        VIF\n",
      "0  Gender   2.028864\n",
      "1  Height  11.623103\n",
      "2  Weight  10.688377\n",
      "\n",
      "Explained Variance Ratio:\n",
      "[0.33996503 0.33345745 0.32657752]\n",
      "\n",
      "Number of components to retain 66% variance: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "data = {\n",
    "    \"Y\":[78.5,74.3,104.3,87.6,95.9,109.2],\n",
    "    \"X1\":[7,1,11,11,7,11],\n",
    "    \"X2\":[26,29,56,31,52,55]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head(6)\n",
    "X=df[[\"X1\",\"X2\"]]\n",
    "Correlation_matrix = X.corr()\n",
    "print(Correlation_matrix)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "\n",
    "#Calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "path = kagglehub.dataset_download(\"yasserh/bmidataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "import kagglehub\n",
    "\n",
    "# Calling the dataset using the above path given\n",
    "data = pd.read_csv(f\"{path}/bmi.csv\")\n",
    "print(data.head())\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "data['Gender'] = data['Gender'].map({'Male':0,'Female':1})\n",
    "X = data[['Gender','Height','Weight']]\n",
    "Correlation_matrix = X.corr()\n",
    "print(Correlation_matrix)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "\n",
    "#Calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "scaler = StandardScaler()   #Creating an empty object called scaler that\n",
    "X_scaled = scaler.fit_transform(X) #fit_transform computes the mean and variance of X\n",
    "                                # and rescales the value to zero mean and unit variance process\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA() #Creating an empty object called PCA that can be used to perform Principal Component Analysis\n",
    "X_pca = pca.fit_transform(X_scaled) #X_scaled is the dataset on which you want to perform PCA\n",
    "\n",
    "# Explained variance ratio to determine the number of components\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Select the number of components to retain (e.g., 95% variance)\n",
    "threshold = 0.66\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "num_components = np.where(cumulative_variance >= threshold)[0][0] + 1\n",
    "\n",
    "print(f\"\\nNumber of components to retain {threshold*100:.0f}% variance: {num_components}\")\n",
    "\n",
    "# Transform the data with the selected number of components\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "# The dataset with reduced multicollinearity\n",
    "X_pca_reduced_df = pd.DataFrame(X_pca_reduced, columns=[f'PC{i+1}' for i in range(num_components)])\n",
    "\n",
    "#Getting Weights (loadings) of each PC\n",
    "pc_weights = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249830df-027c-4f87-b6ff-27a931bf8644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
